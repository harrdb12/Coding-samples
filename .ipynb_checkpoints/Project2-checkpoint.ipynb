{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mysql.connector as sql\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from off campus it MAY/MAY NOT be faster to use a database mirror at 192.168.1.37\n",
    "#mysqlCnx= sql.connect(host='192.168.1.37', \n",
    "mysqlCnx= sql.connect(host='falcon.cs.wfu.edu', \n",
    "                port=3306,user='CSstudent', passwd='CSdeacon', \n",
    "                db='mxm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for the full data set use 237662\n",
    "numLyrics = 237662\n",
    "# for testing only\n",
    "#numLyrics  = 5\n",
    "numHashes = 101\n",
    "#print('loaded tid names from database:', numLyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create and initialize Signature matrix for minhashing\n",
    "M = np.empty([numHashes, numLyrics], dtype=int)\n",
    "M.fill( 2147483647, )   # fill with \"infinity\"\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hash( a, b, row ):\n",
    "    return (a * row + b) % numLyrics\n",
    "\n",
    "# generate coefficients for numHashes hash functions\n",
    "hashCoefficients = np.random.randint(1001, high=2147483647, size=(numHashes,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateSigMatrix( wordID, colNum):\n",
    "    global M\n",
    "    for hashKey in range(numHashes):\n",
    "        hashval = hash( hashCoefficients[hashKey][0], hashCoefficients[hashKey][1], wordID )\n",
    "        if hashval < M[hashKey][colNum]:\n",
    "            M[hashKey][colNum] = hashval\n",
    "    return      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell contains the final step for filling in the signature matrix\n",
    "# for all the lyrics -- \n",
    "# For testing - skip this cell and run the next cell\n",
    "for lyricID in range(numLyrics):\n",
    "\n",
    "    if lyricID % 1000 == 0:\n",
    "        print( \"At lyricID: \", lyricID )\n",
    "        \n",
    "    query = \"select wordID from lyricBags where lyricID = '%s'\"%(lyricID,)\n",
    "    wordInfoDF = pd.read_sql(query, con=mysqlCnx)\n",
    "    \n",
    "    for (_,wordID) in wordInfoDF.itertuples():\n",
    "        updateSigMatrix( wordID, lyricID )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: Only execute this cell for testing purposes.\n",
    "#       This only fills in the signature matrix for 7 lyrics.\n",
    "\n",
    "# This is a test of the process on these 7 selected lyrics by lyricID\n",
    "testLyrics = [ 58584, 86470, 112317, 146341, 166049, 199097, 233196 ]\n",
    "\n",
    "# fill in the signature matrix for these selected lyricIDs\n",
    "# This will result in just a few columns of the minhash matrix being computed\n",
    "for lyricID in testLyrics:\n",
    "    query = \"select wordID from lyricBags where lyricID = '%s'\"%(lyricID,)\n",
    "    wordInfoDF = pd.read_sql(query, con=mysqlCnx)\n",
    "    \n",
    "    for (_,wordID) in wordInfoDF.itertuples():\n",
    "        updateSigMatrix( wordID, lyricID )\n",
    "\n",
    "# show the titles of the specific lyrics selected\n",
    "query = \"select artist, title from lyrics natural join details\" + \\\n",
    "         \" where lyricID in ( '%s', '%s', '%s', '%s', '%s', '%s', '%s' )\" % tuple(testLyrics)\n",
    "results = pd.read_sql(query, con=mysqlCnx)\n",
    "\n",
    "for row in results.itertuples():\n",
    "    print( row[0], row[1].decode('utf-8'), \"\\t\", row[2].decode('utf-8') )\n",
    "print()\n",
    "\n",
    "# print first 20 rows of Signature matrix for these 7 test lyrics\n",
    "for i in range(20):\n",
    "    for lyricNum in range(len(testLyrics)):\n",
    "       print( M[i,testLyrics[lyricNum]], end=\"\\t\" )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# can run this for testing whether the entire table is filled or not\n",
    "testLyrics = [ 58584, 86470, 112317, 146341, 166049, 199097, 233196 ]\n",
    "\n",
    "# show the titles of the specific lyrics selected\n",
    "query = \"select artist, title from lyrics natural join details\" + \\\n",
    "         \" where lyricID in ( '%s', '%s', '%s', '%s', '%s', '%s', '%s' )\" % tuple(testLyrics)\n",
    "results = pd.read_sql(query, con=mysqlCnx)\n",
    "\n",
    "for row in results.itertuples():\n",
    "    print( row[0], row[1].decode('utf-8'), \"\\t\", row[2].decode('utf-8') )\n",
    "print()\n",
    "\n",
    "# print first 20 rows of Signature matrix for these 7 test lyrics\n",
    "for i in range(20):\n",
    "    for lyricNum in range(len(testLyrics)):\n",
    "       print( M[i,testLyrics[lyricNum]], end=\"\\t\" )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save M to a file\n",
    "#np.save( \"M.npy\", M, allow_pickle=True )\n",
    "\n",
    "M = np.load( \"M.npy\" )\n",
    "matrix1 = M[:25]\n",
    "matrix2 = M[25:50]\n",
    "matrix3 = M[50:75]\n",
    "matrix4 = M[75:]\n",
    "pair_matrix = []\n",
    "\n",
    "def create_pairs(input_matrix):\n",
    "    newhashCoefficients = np.random.randint(1001, high=2147483647, size=(input_matrix.shape[0]))\n",
    "    random_constant = np.random.randint(1001, high=2147483647)\n",
    "    dicthash = {}\n",
    "    for i in range(input_matrix.shape[1]):\n",
    "        w = (np.dot(newhashCoefficients,input_matrix[:,i])+random_constant)%1000000000\n",
    "        if w in dicthash:\n",
    "            dicthash[w].append(i)\n",
    "        else:\n",
    "            dicthash[w]=[i]\n",
    "\n",
    "    hash_matches = [v for (k,v) in dicthash.items() if len(v) > 1]\n",
    "    for i in hash_matches:\n",
    "        for j in range(len(i)-1):\n",
    "            for k in range(j+1,len(i)):\n",
    "                if [i[j],i[k]] not in pair_matrix:\n",
    "                    pair_matrix.append([i[j],i[k]]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_pairs(matrix1)\n",
    "create_pairs(matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_pairs(matrix3)\n",
    "create_pairs(matrix4)\n",
    "pair_matrix = sorted(pair_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outfile = open(\"mydata.out\", \"w\")\n",
    "for lyricID in pair_matrix:\n",
    "        \n",
    "    query1 = \"select count(*) from lyricBags as S join lyricBags as T using (wordID) where S.lyricID = '%s' and T.lyricID = '%s'\"%(lyricID[0],lyricID[1])\n",
    "    query2 = \"select count(*) from lyricBags where lyricID = '%s'\"%(lyricID[0])\n",
    "    query3 = \"select count(*) from lyricBags where lyricID = '%s'\"%(lyricID[1])\n",
    "    query4 = \"select distinct details.title from lyricBags natural join lyrics natural join details where lyricID = '%s'\"%(lyricID[0])\n",
    "    query5 = \"select distinct details.title from lyricBags natural join lyrics natural join details where lyricID = '%s'\"%(lyricID[1])\n",
    "    intersection = pd.read_sql(query1, con=mysqlCnx)\n",
    "    total1 = pd.read_sql(query2, con=mysqlCnx)\n",
    "    total2 = pd.read_sql(query3, con=mysqlCnx)\n",
    "    title1 = pd.read_sql(query4, con=mysqlCnx)\n",
    "    title2 = pd.read_sql(query5, con=mysqlCnx)\n",
    "\n",
    "    similarity = intersection/(total1+total2-intersection)\n",
    "    similarity = float(similarity.values)\n",
    "    if similarity >= 0.95:\n",
    "        print(title1['title'][0].decode('utf-8'),'\\t',title2['title'][0].decode('utf-8'),'\\t',similarity, file=outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:csc322622]",
   "language": "python",
   "name": "conda-env-csc322622-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
